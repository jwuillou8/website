---
layout: project
title:  HD Computing / Machine Learning
caption: Encodings and Machine Learning with Sparse Distributed Memories.
description: >
   Experiments on neuroinspired computing embeddings integrated with Deep and Machine Learning
date: '01-05-2019'
image: 
  path: /assets/img/projects/stressgraph2.jpg
  srcset: 
    1920w: /assets/img/projects/stressgraph2.jpg
    960w:  /assets/img/projects/stressgraph2@0,5x.jpg
    480w:  /assets/img/projects/stressgraph2@0,25x.jpg
links:
  - title: Mini Paper
    url: https://github.com/gilgameshjw/HDcomputing/blob/master/Doc/extendHDcomputing.pdf
  - title: Code
    url: https://github.com/gilgameshjw/HDComputing.jl
sitemap: false
---

Machine & Deep Learning and High Dimensional computing have very distinct qualities and advantages. 

In particular, encodings with sparse or dense vector leads to distincts performances and some time astonishing performances, like on [semeval2016](https://github.com/gilgameshjw/HDComputing.jl/blob/master/examples/demoSemevalNB.ipynb). 

See for my work at constellation.ai and our paper for more details and results.

